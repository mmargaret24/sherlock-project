{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a2584dd",
   "metadata": {},
   "source": [
    "# Using Sherlock out-of-the-box\n",
    "This notebook shows how to predict a semantic type for a given table column.\n",
    "The steps are basically:\n",
    "- Download files for word embedding and paragraph vector feature extraction (downloads only once) and initialize feature extraction models.\n",
    "- Extract features from table columns.\n",
    "- Initialize Sherlock.\n",
    "- Make a prediction for the feature representation of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86625d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "from sherlock import helpers\n",
    "from sherlock.deploy.model import SherlockModel\n",
    "from sherlock.functional import extract_features_to_csv\n",
    "from sherlock.features.paragraph_vectors import initialise_pretrained_model, initialise_nltk\n",
    "from sherlock.features.preprocessing import (\n",
    "    extract_features,\n",
    "    convert_string_lists_to_lists,\n",
    "    prepare_feature_extraction,\n",
    "    load_parquet_values,\n",
    ")\n",
    "from sherlock.features.word_embeddings import initialise_word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc6b1a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Environment does not have key: PYTHONHASHSEED\n"
     ]
    }
   ],
   "source": [
    "%env PYTHONHASHSEED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1101303",
   "metadata": {},
   "source": [
    "## Initialize feature extraction models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8682ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing feature extraction by downloading 4 files:\n",
      "        \n",
      " ../sherlock/features/glove.6B.50d.txt, \n",
      " ../sherlock/features/par_vec_trained_400.pkl.docvecs.vectors_docs.npy,\n",
      "        \n",
      " ../sherlock/features/par_vec_trained_400.pkl.trainables.syn1neg.npy, and \n",
      " ../sherlock/features/par_vec_trained_400.pkl.wv.vectors.npy.\n",
      "        \n",
      "All files for extracting word and paragraph embeddings are present.\n",
      "Initialising word embeddings\n",
      "Initialise Word Embeddings process took 0:00:05.222817 seconds.\n",
      "Initialise Doc2Vec Model, 400 dim, process took 0:00:04.139277 seconds. (filename = ../sherlock/features/par_vec_trained_400.pkl)\n",
      "Initialised NLTK, process took 0:00:00.183120 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/mmargaret/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mmargaret/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "prepare_feature_extraction()\n",
    "initialise_word_embeddings()\n",
    "initialise_pretrained_model(400)\n",
    "initialise_nltk()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3b7967",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db04ccf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series(\n",
    "    [\n",
    "        [\"Jane Smith\", \"Lute Ahorn\", \"Anna James\"],\n",
    "        [\"Amsterdam\", \"Haarlem\", \"Zwolle\"],\n",
    "        [\"Chabot Street 19\", \"1200 fifth Avenue\", \"Binnenkant 22, 1011BH\"]\n",
    "    ],\n",
    "    name=\"values\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4875f6c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 [Jane Smith, Lute Ahorn, Anna James]\n",
       "1                         [Amsterdam, Haarlem, Zwolle]\n",
       "2    [Chabot Street 19, 1200 fifth Avenue, Binnenka...\n",
       "Name: values, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7f2c846",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features: 100%|███████████████████████| 3/3 [00:00<00:00, 119.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting 1588 column features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "extract_features(\n",
    "    \"../temporary.csv\",\n",
    "    data\n",
    ")\n",
    "feature_vectors = pd.read_csv(\"../temporary.csv\", dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c42ce71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_[0]-agg-any</th>\n",
       "      <th>n_[0]-agg-all</th>\n",
       "      <th>n_[0]-agg-mean</th>\n",
       "      <th>n_[0]-agg-var</th>\n",
       "      <th>n_[0]-agg-min</th>\n",
       "      <th>n_[0]-agg-max</th>\n",
       "      <th>n_[0]-agg-median</th>\n",
       "      <th>n_[0]-agg-sum</th>\n",
       "      <th>n_[0]-agg-kurtosis</th>\n",
       "      <th>n_[0]-agg-skewness</th>\n",
       "      <th>...</th>\n",
       "      <th>par_vec_390</th>\n",
       "      <th>par_vec_391</th>\n",
       "      <th>par_vec_392</th>\n",
       "      <th>par_vec_393</th>\n",
       "      <th>par_vec_394</th>\n",
       "      <th>par_vec_395</th>\n",
       "      <th>par_vec_396</th>\n",
       "      <th>par_vec_397</th>\n",
       "      <th>par_vec_398</th>\n",
       "      <th>par_vec_399</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.115947</td>\n",
       "      <td>0.022813</td>\n",
       "      <td>-0.129670</td>\n",
       "      <td>0.007136</td>\n",
       "      <td>-0.135551</td>\n",
       "      <td>-0.071779</td>\n",
       "      <td>-0.052227</td>\n",
       "      <td>-0.068066</td>\n",
       "      <td>0.086240</td>\n",
       "      <td>-0.143894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054345</td>\n",
       "      <td>0.023706</td>\n",
       "      <td>-0.165423</td>\n",
       "      <td>-0.014555</td>\n",
       "      <td>-0.058669</td>\n",
       "      <td>0.010671</td>\n",
       "      <td>-0.046186</td>\n",
       "      <td>0.024224</td>\n",
       "      <td>0.037534</td>\n",
       "      <td>-0.086876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021482</td>\n",
       "      <td>0.001564</td>\n",
       "      <td>0.047380</td>\n",
       "      <td>0.118961</td>\n",
       "      <td>-0.093632</td>\n",
       "      <td>0.036631</td>\n",
       "      <td>-0.004065</td>\n",
       "      <td>-0.089170</td>\n",
       "      <td>-0.119149</td>\n",
       "      <td>-0.191951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1588 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_[0]-agg-any  n_[0]-agg-all  n_[0]-agg-mean  n_[0]-agg-var  n_[0]-agg-min  \\\n",
       "0            0.0            0.0             0.0       0.000000            0.0   \n",
       "1            0.0            0.0             0.0       0.000000            0.0   \n",
       "2            1.0            0.0             1.0       0.666667            0.0   \n",
       "\n",
       "   n_[0]-agg-max  n_[0]-agg-median  n_[0]-agg-sum  n_[0]-agg-kurtosis  \\\n",
       "0            0.0               0.0            0.0                -3.0   \n",
       "1            0.0               0.0            0.0                -3.0   \n",
       "2            2.0               1.0            3.0                -1.5   \n",
       "\n",
       "   n_[0]-agg-skewness  ...  par_vec_390  par_vec_391  par_vec_392  \\\n",
       "0                 0.0  ...    -0.115947     0.022813    -0.129670   \n",
       "1                 0.0  ...    -0.054345     0.023706    -0.165423   \n",
       "2                 0.0  ...    -0.021482     0.001564     0.047380   \n",
       "\n",
       "   par_vec_393  par_vec_394  par_vec_395  par_vec_396  par_vec_397  \\\n",
       "0     0.007136    -0.135551    -0.071779    -0.052227    -0.068066   \n",
       "1    -0.014555    -0.058669     0.010671    -0.046186     0.024224   \n",
       "2     0.118961    -0.093632     0.036631    -0.004065    -0.089170   \n",
       "\n",
       "   par_vec_398  par_vec_399  \n",
       "0     0.086240    -0.143894  \n",
       "1     0.037534    -0.086876  \n",
       "2    -0.119149    -0.191951  \n",
       "\n",
       "[3 rows x 1588 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41d44ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9027fa4a",
   "metadata": {},
   "source": [
    "## Initialize Sherlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9ec13ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4j/b74xw8zn3_9dq5pwdxr7vtlr0000gn/T/ipykernel_4058/489084952.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSherlockModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_model_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sherlock\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/[UVA] Thesis/sherlock-project/sherlock/deploy/model.py\u001b[0m in \u001b[0;36minitialize_model_from_json\u001b[0;34m(self, with_weights, model_id)\u001b[0m\n\u001b[1;32m    191\u001b[0m                     \"\"\"\n\u001b[1;32m    192\u001b[0m                 )\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         model.compile(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m    180\u001b[0m         raise ValueError('Load weights is not yet supported with TPUStrategy '\n\u001b[1;32m    181\u001b[0m                          'with steps_per_run greater than 1.')\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m         \u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m    643\u001b[0m   \"\"\"\n\u001b[1;32m    644\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m'keras_version'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m     \u001b[0moriginal_keras_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keras_version'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0moriginal_keras_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "model = SherlockModel();\n",
    "model.initialize_model_from_json(with_weights=True, model_id=\"sherlock\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5551878e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a1ab955",
   "metadata": {},
   "source": [
    "## Predict semantic type for column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc079fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = model.predict(feature_vectors, \"sherlock\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0feb9584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['name', 'city', 'address'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4efc9a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
